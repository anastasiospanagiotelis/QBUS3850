{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style = \"fontsize:400%;text-align:center;\">QBUS3850: Time Series and Forecasting</h1>\n",
    "<h2 style = \"fontsize:300%;text-align:center;\">Forecast Combination</h2>\n",
    "<h3 style = \"fontsize:200%;text-align:center;\">Lecture Notes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style = \"fontsize:300%;text-align:center;\">Forecast Combination</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- A game is to guess the number of jelly beans in a jar.\n",
    "- While individiual guesses are wrong, the average of many guesses will be close to the answer.\n",
    "- In forecasting we can improve forecasts by averaging over different models \n",
    "- The same principle works for expert judgements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src=\"beans.jpeg\" alt=\"beans\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wisdom of the crowd (of forecasters)\n",
    "\n",
    "- In a seminal 1969 paper Bates and Granger propose forecast combination.\n",
    "- Consider the case of two forecasts.\n",
    "- Forecast quality measured by Mean Square Error of forecasts.\n",
    "- They are able to show that\n",
    "  - Combinination weights depend on variances and covariances of forecast errors.\n",
    "  - The combined forecast is better than any individual forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The math\n",
    "\n",
    "Let $\\hat{y}_{1}$ and $\\hat{y}_{2}$ be two forecasts, and $w$ be a combination weight. The combined forecast $\\hat{y}_c$ is given by\n",
    "\n",
    "$$\\hat{y}_{c}=w\\hat{y}_{1}+(1-w)\\hat{y}_{2}$$\n",
    "\n",
    "Also let $\\sigma_1$ and $\\sigma_2$ be the forecast error variances of the two forecasts respectvely.\n",
    "\n",
    "$$\\sigma^2_1 = E\\left[(y-\\hat{y}_{1})^2\\right]\\quad\\textrm{and}\\quad\\sigma^2_2 = E\\left[(y-\\hat{y}_{2})^2\\right]$$\n",
    "\n",
    "This expectation is with respect to forecast errors (not in-sample errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# More detail\n",
    "\n",
    "Each forecast is made at time $t+h$ using information at time $t$. The expectation is with respect to the conditional distribution of $\\hat{y}_{t+h|t}$. For each forecast.\n",
    "\n",
    "$$\\sigma^2 = E_{y_{t+h|t}}\\left[(y_{t+h}-\\hat{y}_{t+h|t})^2\\right]$$\n",
    "\n",
    "If forecasts are unbiased $E_{t+h|t}\\left[\\hat{y}_{t+h|t}\\right]=y_{t+h}$. This means the expected square error is given by\n",
    "\n",
    "$$\\sigma^2 = E_{y_{t+h|t}}\\left[\\left(\\hat{y}_{t+h|t}-E_{t+h|t}[\\hat{y}_{t+h|t}]\\right)^2\\right]$$\n",
    "\n",
    "Each $sigma^2$ is the forecast error variance. From now on let's keep the notation simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expected value of combination\n",
    "\n",
    "\n",
    "$$E\\left[\\hat{y}_{c}\\right]=wE\\left[\\hat{y}_{1}\\right]+(1-w)E\\left[\\hat{y}_{2}\\right]$$\n",
    "\n",
    "If forecasts are unbiased, then\n",
    "\n",
    "$$E\\left[\\hat{y}_{c}\\right]=wy+(1-w)y=y$$\n",
    "\n",
    "Combinations of unbiased forecasts are also unbiased (if weights sum to one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variance of combination\n",
    "\n",
    "$$\\begin{aligned}E\\left[(\\hat{y}_{c}-y)^2\\right]&=E\\left[(w\\hat{y}_1+(1-w)\\hat{y}_2-y)^2\\right]\\\\&=E\\left[(w\\hat{y}_1+(1-w)\\hat{y}_2-wy-(1-w)y)^2\\right]\\\\&=E\\left[\\left(w(\\hat{y}_{1}-y)+(1-w)(\\hat{y}_{2}-y)\\right)^2\\right]\\\\&=E\\left[w^2(\\hat{y}_{1}-y)^2+2w(1-w)(\\hat{y}_{1}-y)(\\hat{y}_{2}-y)+(1-w)^2(\\hat{y}_{2}-y)^2\\right]\\\\&=w^2\\sigma^2_1+2w(1-w)\\rho\\sigma_1\\sigma_2+(1-w^2)\\sigma_2^2\\end{aligned}$$\n",
    "\n",
    "Where $\\rho$ is the correlation between forecasts. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimal Combination Weights\n",
    "\n",
    "Minimising the above equation for $w$ gives the optimal weight\n",
    "\n",
    "$$w^{(\\textrm{opt})}=\\frac{\\sigma^2_2-\\rho\\sigma_1\\sigma_2}{\\sigma_1^2+\\sigma_2^2+2\\rho\\sigma_1\\sigma_2}$$\n",
    "\n",
    "For the case of uncorrelated forecasts this simplifies to:\n",
    "\n",
    "$$w^{(\\textrm{opt})}=\\frac{\\sigma^2_2}{\\sigma_1^2+\\sigma_2^2}$$\n",
    "\n",
    "It can be proven that the optimal combination weights have a smaller variance compared to any individual forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your turn...\n",
    "\n",
    "- When $\\sigma_1$ is high is $w^{(\\textrm{opt})}$ bigger or smaller? \n",
    "  - Does this make sense?\n",
    "- When $\\sigma_2$ is high is $w^{(\\textrm{opt})}$ bigger or smaller? \n",
    "  - Does this make sense?\n",
    "- When $\\rho$ is high is $w^{(\\textrm{opt})}$ bigger or smaller? \n",
    "  - Does this make sense?\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The general case\n",
    "\n",
    "For more than two forecasts, the objective function is\n",
    "\n",
    "$$\\boldsymbol{w}^{(\\textrm{opt})}=\\underset{\\mathbf{w}}{argmin}\\,\\mathbf{w}'\\boldsymbol{\\Sigma}\\mathbf{w}\\:\\textrm{s.t}\\:\\boldsymbol{\\iota}'\\mathbf{w}=1$$\n",
    "\n",
    "Where $\\boldsymbol{\\iota}$ is a column of 1's. This can be solved as\n",
    "\n",
    "$$\\boldsymbol{w}^{(\\textrm{opt})}=\\frac{{\\boldsymbol{\\Sigma^{-1}\\iota}}}{\\boldsymbol{\\iota'\\Sigma^{-1}\\iota}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimating $\\sigma_j$ and $\\rho$\n",
    "\n",
    "- In practice the forecast variances are not known and need to be estimated.\n",
    "- For statistical models we have expressions for forecast variance, but this is not always available.\n",
    "  - For example consider expert judgments\n",
    "- As long as we have forecasts and true values  (e.g. via a rolling window), we can estimate $\\sigma_j$ and $\\rho$ and use these to calculate combination weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Strategies (2 forecast case)\n",
    "\n",
    "Let $\\hat\\sigma_1$ and $\\hat\\sigma_2$ be the mean square (forecast) errors. Let $T$ be the time at which we want to form combination weighs. methods include:\n",
    "\n",
    "- $w_T=\\frac{\\hat\\sigma_2}{\\hat\\sigma_1+\\hat\\sigma_2}$\n",
    "- $w_T=\\gamma w_{T-1}+(1-\\gamma)\\frac{\\hat\\sigma_2}{\\hat\\sigma_1+\\hat\\sigma_2}$\n",
    "\n",
    "Alternative variances (and covariances) can be computed as weighted sums with higher weights for more recent errors\n",
    "\n",
    "$$\\tilde\\sigma^2_1=\\sum \\alpha_t(y_t-\\hat{y}_{1,t})^2$$\n",
    "\n",
    "where $\\alpha_t$ is increasing in $t$ and a similar expression is used to estimate the $\\tilde\\sigma^2_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style = \"fontsize:300%;text-align:center;\">Forecast Combination Puzzle</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The puzzle\n",
    "\n",
    "- The theory shows that equal weights (i.e. 1/K) is not guaranteed to be optimal.\n",
    "- However years of forecasting practice and research have shown that equal weights often outperform so-called optimal weights.\n",
    "- This is known as the *forecast combination puzzle*.\n",
    "- There are several explanations of the puzzle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explanation\n",
    "\n",
    "- Recall from a few slides back, that to show combinations are unbiased\n",
    "\n",
    "$$E\\left[\\hat{y}_{c}\\right]=wE\\left[\\hat{y}_{1}\\right]+(1-w)E\\left[\\hat{y}_{2}\\right]$$\n",
    "\n",
    "- This line of math assumes that $w$ is fixed. However as we have seen, it is often estimated from data.\n",
    "- The need to estimate $w$ results in a bias in forecast combination.\n",
    "- In constrast, equal weights are truly non-random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visually\n",
    "\n",
    "- The bottom curve shows the expected mean square error of combined forecasts against the value of the weight.\n",
    "  - F is the optimal point\n",
    "  - E is equal weights\n",
    "- The top curve is higher due to randomness of weights.\n",
    "  - R is the optimal point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src=\"puzzle.png\" alt=\"puzzle\" width=\"900\"/>\n",
    "\n",
    "Source: [Claeskens et al. (2016)](https://www.sciencedirect.com/science/article/abs/pii/S0169207016000327)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# General case uncorrelated forecasts\n",
    "\n",
    "If forecasts are uncorrelated, then $\\Sigma$ is diagonal and the weight is proportional to the inverse forecast error variance. For weight $j$ when there are $K$ forecasts in total\n",
    "\n",
    "$$w_j=\\frac{1/\\sigma^2_j}{\\sum\\limits_{i=1}^K1/\\sigma_k^2}$$\n",
    "\n",
    "This provides a simple way of getting weights that does not rely on estimating covariances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shrink to equal weights\n",
    "\n",
    "Diebold and Shin (2019) propose using regularisation to shrink towards equal weights. Rewrite problem as a regression model\n",
    "\n",
    "$y=w_1\\hat{y}_1+w_2\\hat{y}_2+w_3\\hat{y}_3+\\dots+w_k\\hat{y}_K+\\epsilon$\n",
    "\n",
    "Rather than minimise\n",
    "\n",
    "$RSS = \\sum(y-w_1\\hat{y}_1+w_2\\hat{y}_2+w_3\\hat{y}_3+\\dots+w_k\\hat{y}_K)^2$\n",
    "\n",
    "Add a L1 or L2 penalty on w's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shrink to equal weights\n",
    "\n",
    "- Egalitarian Ridge\n",
    "\n",
    "$$\\mathbf{w}^{(er)}=\\underset{\\mathbf{w}}{argmin}\\left(RSS+\\sum\\limits_{k=1}^K(w_k-(1/K))^2\\right)$$\n",
    "\n",
    "- Egalitarian Lasso\n",
    "\n",
    "$$\\mathbf{w}^{(el)}=\\underset{\\mathbf{w}}{argmin}\\left(RSS+\\sum\\limits^K_{k=1}|w_k-(1/K)|\\right)$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "scroll": true,
   "start_slideshow_at": "beginning"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
